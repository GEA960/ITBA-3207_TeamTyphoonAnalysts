{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e4b717",
   "metadata": {},
   "source": [
    "Humanitarian Data Exchange Data set about Philippines (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b73bade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Importing the matplotlib library and renaming it as plt.\n",
    "\n",
    "import matplotlib.pyplot as plt #Importing pandas library\n",
    "\n",
    "data=pd.read_excel(r'200204_philippines-2019-events-data.xlsx_3FAWSAccessKeyId=AKIAXYC32WNARK756OUG_Expires=1644193427_Signature=hFTPcWroN6S3M2pX40ObWvu24p8=.xlsx', sheet_name=\"Tropical Cyclones\")\n",
    "\n",
    "df=pd.DataFrame(data) #convert dataset excel into dataframe\n",
    "\n",
    "#selecting all needed and specific columns from original dataframe/dataset and creating new dataframe named new_df\n",
    "new_df = df.iloc[:,[0,2,4,6,7,8,9,10,12,13,14,15,16,17,18,19,20,21,22,23]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f3591e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 687 entries, 0 to 686\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Region                    686 non-null    object        \n",
      " 1   Province                  686 non-null    object        \n",
      " 2   City_Mun                  686 non-null    object        \n",
      " 3   Year                      687 non-null    int64         \n",
      " 4   Incident                  687 non-null    object        \n",
      " 5   Date Occurred             687 non-null    datetime64[ns]\n",
      " 6   2015 Population           687 non-null    int64         \n",
      " 7   Affected_FAM              687 non-null    int64         \n",
      " 8   Affected_PERs             686 non-null    float64       \n",
      " 9   Inside_EC_Fam_Cum         659 non-null    float64       \n",
      " 10  Inside_EC_Fam_Now         687 non-null    int64         \n",
      " 11  Inside_EC_Per_Cum         659 non-null    float64       \n",
      " 12  Inside_EC_Per_Now         686 non-null    float64       \n",
      " 13  Outside_EC_Fam_Cum        659 non-null    float64       \n",
      " 14  Outside_EC_Fam_Now        659 non-null    float64       \n",
      " 15  Outside_EC_Pers_Cum       659 non-null    float64       \n",
      " 16  Outside_EC_Per_Now        687 non-null    int64         \n",
      " 17  Totally damaged houses    687 non-null    int64         \n",
      " 18  Partially damaged houses  686 non-null    float64       \n",
      " 19  IDP_Cum                   687 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(7), object(4)\n",
      "memory usage: 107.5+ KB\n"
     ]
    }
   ],
   "source": [
    "new_df.info() # info() function was used to get an understanding of which aspects of the dataset need cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d5c4b7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region                       1\n",
       "Province                     1\n",
       "City_Mun                     1\n",
       "Year                         0\n",
       "Incident                     0\n",
       "Date Occurred                0\n",
       "2015 Population              0\n",
       "Affected_FAM                 0\n",
       "Affected_PERs                1\n",
       "Inside_EC_Fam_Cum           28\n",
       "Inside_EC_Fam_Now            0\n",
       "Inside_EC_Per_Cum           28\n",
       "Inside_EC_Per_Now            1\n",
       "Outside_EC_Fam_Cum          28\n",
       "Outside_EC_Fam_Now          28\n",
       "Outside_EC_Pers_Cum         28\n",
       "Outside_EC_Per_Now           0\n",
       "Totally damaged houses       0\n",
       "Partially damaged houses     1\n",
       "IDP_Cum                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().sum() #checking for total null values. The resulted values or rows that had null values will be subjected to cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1e360230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To clean the dataframe and remove the object data string columns (Region, Province, City Mun) which had three null values, dropna() function was used.\n",
    "\n",
    "new_df = new_df.dropna(subset=['Region', 'Province', 'City_Mun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9cdfcda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region                       1\n",
       "Province                     1\n",
       "City_Mun                     1\n",
       "Year                         0\n",
       "Incident                     0\n",
       "Date Occurred                0\n",
       "2015 Population              0\n",
       "Affected_FAM                 0\n",
       "Affected_PERs                1\n",
       "Inside_EC_Fam_Cum           28\n",
       "Inside_EC_Fam_Now            0\n",
       "Inside_EC_Per_Cum           28\n",
       "Inside_EC_Per_Now            1\n",
       "Outside_EC_Fam_Cum          28\n",
       "Outside_EC_Fam_Now          28\n",
       "Outside_EC_Pers_Cum         28\n",
       "Outside_EC_Per_Now           0\n",
       "Totally damaged houses       0\n",
       "Partially damaged houses     1\n",
       "IDP_Cum                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After dropping all null values of object string data types, isnull() function were again used to check if the null row(s) was dropped. As the table display below, all object string null rows were removed. However, there are still null values for the int data types columns on the dataframe. This null values are also subjected for cleaning.\n",
    "new_df.isnull().sum() #checking for total null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2b6acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the results above, there are a number of int data type null values that need to be cleaned. And pandas can only clean the dataframe if all rows has values specially for integers. All object data types are already have no null values, which they are all strings. Thus, fillna() function was used to replace null values to zero for smooth data analysis.\n",
    "new_df = new_df.fillna(0) # replace NaN with zero value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b295d458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region                       1\n",
       "Province                     1\n",
       "City_Mun                     1\n",
       "Year                         0\n",
       "Incident                     0\n",
       "Date Occurred                0\n",
       "2015 Population              0\n",
       "Affected_FAM                 0\n",
       "Affected_PERs                1\n",
       "Inside_EC_Fam_Cum           28\n",
       "Inside_EC_Fam_Now            0\n",
       "Inside_EC_Per_Cum           28\n",
       "Inside_EC_Per_Now            1\n",
       "Outside_EC_Fam_Cum          28\n",
       "Outside_EC_Fam_Now          28\n",
       "Outside_EC_Pers_Cum         28\n",
       "Outside_EC_Per_Now           0\n",
       "Totally damaged houses       0\n",
       "Partially damaged houses     1\n",
       "IDP_Cum                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().sum() #checking for total null values\n",
    "\n",
    "#After all of these data cleaning processes, the final dataframe for analysis were create and aas named \"new_df\". And from the results below of isnull() function from the new dataframe, there are now no null values from within the data frame. Thus, data analysis would be smooth and no errors can occur on the latter part of this EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d303337b",
   "metadata": {},
   "source": [
    "    1. Determine the top 5 typhoons from 2019 that brought the greatest number of infrastructure casualties to the Provinces in the Philippines based from Totally Damaged Houses x variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f7283dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Totally damaged houses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TY Tisoy</th>\n",
       "      <td>68104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TY Ursula</th>\n",
       "      <td>60483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS Quiel</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS Hanna</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD Marilyn</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Totally damaged houses\n",
       "Incident                          \n",
       "TY Tisoy                     68104\n",
       "TY Ursula                    60483\n",
       "TS Quiel                        59\n",
       "TS Hanna                        56\n",
       "TD Marilyn                      44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cyclone=df.groupby(\"Incident\")\n",
    "dhouse=cyclone[\"Totally damaged houses\"].sum()\n",
    "typ=pd.DataFrame(dhouse)\n",
    "\n",
    "cycph=typ.sort_values(by=\"Totally damaged houses\", ascending=False)\n",
    "tdh=cycph.head(5)\n",
    "display(tdh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2800e505",
   "metadata": {},
   "source": [
    "2. Acquire the data about the Provinces who had the greatest number of affected individuals per typhoon (Affected_Pers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6bad0ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Province'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#top 5 typhoons from 2019 that brought the greatest number of infrastructure casualties to the Provinces in the Philippines \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ByProvince\u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProvince\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m TotalData \u001b[38;5;241m=\u001b[39m ByProvince[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAffected_PERs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      4\u001b[0m data\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(TotalData)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7707\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7709\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7710\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7711\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7715\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7718\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Province'"
     ]
    }
   ],
   "source": [
    "#top 5 typhoons from 2019 that brought the greatest number of infrastructure casualties to the Provinces in the Philippines \n",
    "ByProvince= df.groupby('Province')\n",
    "TotalData = ByProvince['Affected_PERs'].sum()\n",
    "data= pd.DataFrame(TotalData)\n",
    "SortedData= data.sort_values(by='Affected_PERs',ascending=False)\n",
    "result= SortedData.head(5)\n",
    "display(result)\n",
    "\n",
    "#data graphing \n",
    "totalaffected = [772162, 622951, 602234, 504447, 483308]\n",
    "index = ['Leyte', 'Capiz', 'Northern Samar',\n",
    "         'Aklan', 'Western Samar']\n",
    "df = pd.DataFrame({'totalaffected': totalaffected,\n",
    "                   'province': province}, index=index)\n",
    "ax = df.plot.barh(y='totalaffected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f58028",
   "metadata": {},
   "source": [
    "3. Get the information that shows the top 5 municipalities who were most affected by typhoons from the year 2019.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2728eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affected_PERs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Mun</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CITY OF ROXAS (CAPITAL)</th>\n",
       "      <td>168580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daraga (Locsin)</th>\n",
       "      <td>126595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CITY OF CATBALOGAN (CAPITAL)</th>\n",
       "      <td>122572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CITY OF TACLOBAN (CAPITAL)</th>\n",
       "      <td>119918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catarman (capital)</th>\n",
       "      <td>106424.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Affected_PERs\n",
       "City_Mun                                   \n",
       "CITY OF ROXAS (CAPITAL)            168580.0\n",
       "Daraga (Locsin)                    126595.0\n",
       "CITY OF CATBALOGAN (CAPITAL)       122572.0\n",
       "CITY OF TACLOBAN (CAPITAL)         119918.0\n",
       "Catarman (capital)                 106424.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ByMuni= df.groupby('City_Mun')\n",
    "TotalData=ByMuni['Affected_PERs'].sum()\n",
    "data = pd.DataFrame(TotalData)\n",
    "SortedData = data.sort_values(by='Affected_PERs',ascending=False)\n",
    "result= SortedData.head(5)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa6416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
